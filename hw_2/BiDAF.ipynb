{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BiDAF.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y-Jm6C5A1SDn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip -qq install torch\n",
        "!pip -qq install torchtext\n",
        "!pip -qq install spacy\n",
        "!python -m spacy download en\n",
        "!python -m spacy download en_core_web_sm"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JPuevhum1_r5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget https://raw.githubusercontent.com/svinkapeppa/boolq/master/train.jsonl\n",
        "!wget https://raw.githubusercontent.com/svinkapeppa/boolq/master/dev.jsonl"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QhtfHTbR1nuW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import en_core_web_sm\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "from torchtext.vocab import Vectors\n",
        "from torchtext.data import Example, Field, Dataset, NestedField, BucketIterator"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HvrX9D37_LQG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class FastText(Vectors):\n",
        "    def __init__(self, **kwargs):\n",
        "        name = os.path.basename(kwargs[\"url\"])\n",
        "        super(FastText, self).__init__(name, **kwargs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TNqQlDf0_3xW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vectors = FastText(url=\"https://dl.fbaipublicfiles.com/fasttext/vectors-wiki/wiki.en.vec\", max_vectors=30000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XP2pF_tb113z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nlp = en_core_web_sm.load()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "--bmUsLa2LV3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DataLoader:\n",
        "    def __init__(self):\n",
        "        self.char_field = NestedField(\n",
        "            Field(batch_first=True, tokenize=list, lower=True),\n",
        "            init_token=\"<SOS>\",\n",
        "            eos_token=\"<EOS>\",\n",
        "            tokenize=\"spacy\",\n",
        "        )\n",
        "        self.word_field = Field(\n",
        "            init_token=\"<SOS>\",\n",
        "            eos_token=\"<EOS>\",\n",
        "            lower=True,\n",
        "            tokenize=\"spacy\",\n",
        "        )\n",
        "        self.target_field = Field(\n",
        "            is_target=True,\n",
        "            sequential=False,\n",
        "            use_vocab=False,\n",
        "        )\n",
        "\n",
        "        self.fields = [\n",
        "                (\"question_char\", self.char_field),\n",
        "                (\"context_char\", self.char_field),\n",
        "                (\"question\", self.word_field),\n",
        "                (\"context\", self.word_field),\n",
        "                (\"answer\", self.target_field),\n",
        "        ]\n",
        "        self.dict_fields = {\n",
        "            \"context\": [(\"context_char\", self.char_field), (\"context\", self.word_field)],\n",
        "            \"question\": [(\"question_char\", self.char_field), (\"question\", self.word_field)],\n",
        "            \"answer\": (\"answer\", self.target_field),\n",
        "        }\n",
        "\n",
        "    def create_dataset(self, path: str = None) -> Dataset:\n",
        "        df = pd.read_json(path, lines=True, orient=\"records\")\n",
        "\n",
        "        data = pd.DataFrame()\n",
        "        data[\"context\"] = df[\"title\"] + \" \" + df[\"passage\"]\n",
        "        data[\"question\"] = df[\"question\"]\n",
        "        data[\"answer\"] = df[\"answer\"]\n",
        "\n",
        "        items = data.to_dict(\"records\")\n",
        "\n",
        "        return Dataset([Example.fromdict(item, fields=self.dict_fields) for item in items], self.fields)\n",
        "\n",
        "    def build(self, train_path: str = None, dev_path: str = None, vectors: Vectors = None) -> None:\n",
        "        self.train = self.create_dataset(path=train_path)\n",
        "        self.dev = self.create_dataset(path=dev_path)\n",
        "\n",
        "        self.char_field.build_vocab(self.train)\n",
        "        self.word_field.build_vocab(self.train, vectors=vectors)\n",
        "\n",
        "        pos, ner = [], []\n",
        "        ind2pos, ind2ner = [], []\n",
        "\n",
        "        for data in self.train:\n",
        "            doc = nlp(\" \".join(data.question) + \" \" + \" \".join(data.context))\n",
        "\n",
        "            pos.extend([token.pos_ for token in doc])\n",
        "            ner.extend([token.label_ for token in doc.ents])\n",
        "\n",
        "            ind2pos.extend([(self.word_field.vocab.stoi[str(token)], token.pos_) for token in doc])\n",
        "            ind2ner.extend([(self.word_field.vocab.stoi[str(token)], token.label_) for token in doc.ents])\n",
        "\n",
        "        self.pos_vocab = {tag: i for i, tag in enumerate(set(pos))}\n",
        "        self.ner_vocab = {tag: i + 1 for i, tag in enumerate(set(ner))}\n",
        "        self.ner_vocab[\"<UNK>\"] = 0\n",
        "\n",
        "        self.ind2pos = {tag[0]: self.pos_vocab[tag[1]] for tag in ind2pos}\n",
        "        self.ind2ner = {tag[0]: self.ner_vocab[tag[1]] for tag in ind2ner}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DwR5LVWI2M1B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loader = DataLoader()\n",
        "loader.build(train_path=\"train.jsonl\", dev_path=\"dev.jsonl\", vectors=vectors)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ft76EYRw3OFc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_iter = BucketIterator(loader.train, batch_size=32, shuffle=True, sort_key=lambda x: len(x.context))\n",
        "dev_iter = BucketIterator(loader.dev, batch_size=128, shuffle=True, sort_key=lambda x: len(x.context))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H620cxLB37h9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Model(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        weights,\n",
        "        char_vocab_size: int = None,\n",
        "        char_emb_dim: int = None,\n",
        "        char_hidden_size: int = None,\n",
        "        char_kernel_size: int = None,\n",
        "        emb_dim: int = None,\n",
        "        hidden_size: int = None,\n",
        "        dropout: float = None,\n",
        "    ):\n",
        "        super().__init__()\n",
        "\n",
        "        self.char_vocab_size = char_vocab_size\n",
        "        self.char_emb_dim = char_emb_dim\n",
        "        self.char_hidden_size = char_hidden_size\n",
        "        self.char_kernel_size = char_kernel_size\n",
        "\n",
        "        self.emb_dim = emb_dim\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        self.char_emb = nn.Embedding(self.char_vocab_size, self.char_emb_dim)\n",
        "        self.word_emb = nn.Embedding.from_pretrained(weights, freeze=True)\n",
        "\n",
        "        self.char_conv = nn.Conv2d(1, self.char_hidden_size, (self.char_emb_dim, self.char_kernel_size))\n",
        "\n",
        "        self.alpha = nn.Sequential(\n",
        "            nn.Dropout(p=dropout),\n",
        "            nn.Linear(6 * self.hidden_size, 1)\n",
        "        )\n",
        "\n",
        "        self.contextual_lstm = nn.LSTM(\n",
        "            input_size=self.emb_dim + self.char_hidden_size,\n",
        "            hidden_size=self.hidden_size,\n",
        "            bidirectional=True,\n",
        "            batch_first=True,\n",
        "            dropout=dropout\n",
        "        )\n",
        "        self.modeling_lstm_first = nn.LSTM(\n",
        "            input_size=8 * self.hidden_size,\n",
        "            hidden_size=self.hidden_size,\n",
        "            bidirectional=True,\n",
        "            batch_first=True,\n",
        "            dropout=dropout\n",
        "        )\n",
        "        self.modeling_lstm_second = nn.LSTM(\n",
        "            input_size=2 * self.hidden_size,\n",
        "            hidden_size=self.hidden_size,\n",
        "            bidirectional=True,\n",
        "            batch_first=True,\n",
        "            dropout=dropout\n",
        "        )\n",
        "        self.lstm = nn.LSTM(\n",
        "            input_size=10 * hidden_size,\n",
        "            hidden_size=self.hidden_size,\n",
        "            bidirectional=True,\n",
        "            batch_first=True,\n",
        "            dropout=dropout\n",
        "        )\n",
        "\n",
        "        self.out = nn.Sequential(\n",
        "            nn.Dropout(p=dropout),\n",
        "            nn.Linear(4 * hidden_size, 2)\n",
        "        )\n",
        "\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "\n",
        "    def embed(self, batch):\n",
        "        batch_size = batch.size(0)\n",
        "\n",
        "        emb = self.char_emb(batch)\n",
        "        emb = self.dropout(emb)\n",
        "\n",
        "        emb = emb.transpose(2, 3)\n",
        "        emb = emb.view(-1, self.char_emb_dim, emb.size(3)).unsqueeze(1)\n",
        "\n",
        "        emb = self.char_conv(emb).squeeze()\n",
        "        emb = F.max_pool1d(emb, emb.size(2)).squeeze()\n",
        "\n",
        "        emb = emb.view(batch_size, -1, self.char_hidden_size)\n",
        "\n",
        "        return emb\n",
        "\n",
        "    def attention(self, context, question):\n",
        "        tensor = torch.cat([\n",
        "            context.unsqueeze(2).expand(context.size(0), context.size(1), question.size(1), -1),\n",
        "            question.unsqueeze(1).expand(context.size(0), context.size(1), question.size(1), -1),\n",
        "            context.unsqueeze(2) * question.unsqueeze(1)\n",
        "        ], dim=-1)\n",
        "        s = self.alpha(tensor).squeeze()\n",
        "\n",
        "        a = F.softmax(s, dim=2)\n",
        "        context_question_attention = torch.bmm(a, question)\n",
        "\n",
        "        b = F.softmax(torch.max(s, dim=2)[0], dim=1).unsqueeze(1)\n",
        "        question_context_attention = torch.bmm(b, context).squeeze()\n",
        "        question_context_attention = question_context_attention.unsqueeze(1).expand(-1, context.size(1), -1)\n",
        "\n",
        "        result = torch.cat([\n",
        "                      context,\n",
        "                      context_question_attention,\n",
        "                      context * context_question_attention,\n",
        "                      context * question_context_attention\n",
        "        ], dim=-1)\n",
        "\n",
        "        return result\n",
        "\n",
        "    def forward(self, batch):\n",
        "        context_char_emb = self.embed(batch.context_char)\n",
        "        question_char_emb = self.embed(batch.question_char)\n",
        "        \n",
        "        context_word_emb = self.word_emb(batch.context.transpose(0, 1))\n",
        "        question_word_emb = self.word_emb(batch.question.transpose(0, 1))\n",
        "\n",
        "        context = torch.cat([context_char_emb, context_word_emb], dim=-1)\n",
        "        question = torch.cat([question_char_emb, question_word_emb], dim=-1)\n",
        "\n",
        "        context, _ = self.contextual_lstm(context)\n",
        "        question, _ = self.contextual_lstm(question)\n",
        "\n",
        "        g = self.attention(context, question)\n",
        "\n",
        "        features, _ = self.modeling_lstm_first(g)\n",
        "        features, _ = self.modeling_lstm_second(features)\n",
        "\n",
        "        _, features = self.lstm(torch.cat([g, features], dim=-1))\n",
        "        features = torch.cat((\n",
        "            features[0].permute(1, 0, 2).reshape(batch.context.size(1), 2 * self.hidden_size),\n",
        "            features[1].permute(1, 0, 2).reshape(batch.context.size(1), 2 * self.hidden_size)\n",
        "        ), dim=1)\n",
        "\n",
        "        out = self.out(features)\n",
        "\n",
        "        return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oZX9oy0W38bc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ModelTrainer:\n",
        "    def __init__(self, model, criterion, optimizer):\n",
        "        self.model = model\n",
        "        self.criterion = criterion\n",
        "        self.optimizer = optimizer\n",
        "        \n",
        "    def on_epoch_begin(self, is_train, name, batches_count) -> None:\n",
        "        self.epoch_loss = 0\n",
        "        self.correct_count, self.total_count = 0, 0\n",
        "        self.is_train = is_train\n",
        "        self.name = name\n",
        "        self.batches_count = batches_count\n",
        "        self.model.train(is_train)\n",
        "        \n",
        "    def on_epoch_end(self) -> str:\n",
        "        return '{:>5s} Loss = {:.5f}, Accuracy = {:.2%}'.format(\n",
        "            self.name, self.epoch_loss / self.batches_count, self.correct_count / self.total_count\n",
        "        )\n",
        "        \n",
        "    def on_batch(self, batch) -> str:\n",
        "        logits = self.model(batch)\n",
        "        target = batch.answer\n",
        "        prediction = torch.max(logits, axis=1)[1]\n",
        "\n",
        "        loss = self.criterion(logits, target)\n",
        "\n",
        "        self.total_count += prediction.size(0)\n",
        "        self.correct_count += torch.sum(prediction == target).item()\n",
        "\n",
        "        if self.is_train:\n",
        "            loss.backward()\n",
        "            nn.utils.clip_grad_norm_(self.model.parameters(), 0.5)\n",
        "            self.optimizer.step()\n",
        "            self.optimizer.zero_grad()\n",
        "\n",
        "        self.epoch_loss += loss.item()\n",
        "\n",
        "        return '{:>5s} Loss = {:.5f}, Accuracy = {:.2%}'.format(\n",
        "            self.name, loss.item(), torch.sum(prediction == target).item() / prediction.size(0)\n",
        "        )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oGFjz3RU3-Ud",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tqdm.get_lock().locks = []\n",
        "\n",
        "def do_epoch(\n",
        "    trainer: ModelTrainer = None,\n",
        "    data_iter: BucketIterator = None,\n",
        "    is_train: bool = None,\n",
        "    name: str = None\n",
        ") -> None:\n",
        "    trainer.on_epoch_begin(is_train=is_train, name=name, batches_count=len(data_iter))\n",
        "\n",
        "    with torch.autograd.set_grad_enabled(is_train):\n",
        "        with tqdm(total=trainer.batches_count) as progress_bar:\n",
        "            for i, batch in enumerate(data_iter):\n",
        "                batch_progress = trainer.on_batch(batch=batch)\n",
        "\n",
        "                progress_bar.update()\n",
        "                progress_bar.set_description(batch_progress)\n",
        "\n",
        "            epoch_progress = trainer.on_epoch_end()\n",
        "\n",
        "            progress_bar.set_description(epoch_progress)\n",
        "            progress_bar.refresh()\n",
        "\n",
        "def fit(\n",
        "    trainer: ModelTrainer = None,\n",
        "    train_iter: BucketIterator = None,\n",
        "    epochs_count: int = None,\n",
        "    dev_iter: BucketIterator = None\n",
        ") -> None:\n",
        "    best_val_loss = None\n",
        "\n",
        "    for epoch in range(epochs_count):\n",
        "        try:\n",
        "            name_prefix = '[{} / {}] '.format(epoch + 1, epochs_count)\n",
        "            do_epoch(trainer=trainer, data_iter=train_iter, is_train=True, name=name_prefix + 'Train:')\n",
        "\n",
        "            if not dev_iter is None:\n",
        "                do_epoch(trainer=trainer, data_iter=dev_iter, is_train=False, name=name_prefix + '  Val:')\n",
        "        except KeyboardInterrupt:\n",
        "            print(\"Early stopping\")\n",
        "            return"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e-M0VHHI3_rD",
        "colab_type": "code",
        "outputId": "51ba11f2-de79-412d-e596-a1944d490b5a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "weights = loader.word_field.vocab.vectors\n",
        "model = Model(\n",
        "    weights=weights,\n",
        "    char_vocab_size=len(loader.char_field.vocab),\n",
        "    char_emb_dim=15,\n",
        "    char_hidden_size=15,\n",
        "    char_kernel_size=5,\n",
        "    emb_dim=300,\n",
        "    hidden_size=64,\n",
        "    dropout=0.3\n",
        ")\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "trainer = ModelTrainer(model=model, criterion=criterion, optimizer=optimizer)\n",
        "fit(trainer=trainer, train_iter=train_iter, epochs_count=5, dev_iter=dev_iter)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1 / 5] Train: Loss = 0.66095, Accuracy = 62.03%: 100%|██████████| 295/295 [1:06:55<00:00, 13.61s/it]\n",
            "[1 / 5]   Val: Loss = 0.64521, Accuracy = 62.26%: 100%|██████████| 26/26 [01:54<00:00,  4.39s/it]\n",
            "[2 / 5] Train: Loss = 0.63368, Accuracy = 64.48%: 100%|██████████| 295/295 [1:06:58<00:00, 13.62s/it]\n",
            "[2 / 5]   Val: Loss = 0.68701, Accuracy = 62.35%: 100%|██████████| 26/26 [01:52<00:00,  4.33s/it]\n",
            "[3 / 5] Train: Loss = 0.60286, Accuracy = 67.36%: 100%|██████████| 295/295 [1:06:55<00:00, 13.61s/it]\n",
            "[3 / 5]   Val: Loss = 0.63903, Accuracy = 64.25%: 100%|██████████| 26/26 [01:50<00:00,  4.24s/it]\n",
            "[4 / 5] Train: Loss = 0.56484, Accuracy = 70.60%: 100%|██████████| 295/295 [1:08:35<00:00, 13.95s/it]\n",
            "[4 / 5]   Val: Loss = 0.65187, Accuracy = 64.62%: 100%|██████████| 26/26 [01:58<00:00,  4.57s/it]\n",
            "[5 / 5] Train: Loss = 0.51873, Accuracy = 74.32%: 100%|██████████| 295/295 [1:06:45<00:00, 13.58s/it]\n",
            "[5 / 5]   Val: Loss = 0.74313, Accuracy = 61.38%: 100%|██████████| 26/26 [01:55<00:00,  4.44s/it]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C77JQVLz16Z_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}